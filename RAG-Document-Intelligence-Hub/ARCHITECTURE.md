# ğŸ—ï¸ RAG Demo Architecture

## ğŸ“ System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Streamlit Frontend                         â”‚
â”‚                        (app/main.py)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  Upload Mode      â”‚          â”‚  Pre-loaded Mode       â”‚    â”‚
â”‚  â”‚  ğŸ“¤              â”‚          â”‚  ğŸ“š                    â”‚    â”‚
â”‚  â”‚                   â”‚          â”‚                        â”‚    â”‚
â”‚  â”‚  â€¢ Drag & Drop    â”‚          â”‚  â€¢ data/ directory     â”‚    â”‚
â”‚  â”‚  â€¢ PDF, CSV, TXT  â”‚          â”‚  â€¢ .txt files          â”‚    â”‚
â”‚  â”‚  â€¢ MD files       â”‚          â”‚  â€¢ Discovery prompts   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚           â”‚                              â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                              â”‚
            â–¼                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG Engine (rag_engine.py)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ process_uploaded_    â”‚      â”‚ load_documents()     â”‚       â”‚
â”‚  â”‚ file()               â”‚      â”‚ create_vectorstore() â”‚       â”‚
â”‚  â”‚                      â”‚      â”‚                      â”‚       â”‚
â”‚  â”‚ 1. extract_text()    â”‚      â”‚ 1. Load .txt files   â”‚       â”‚
â”‚  â”‚ 2. chunk_text()      â”‚      â”‚ 2. Chunk documents   â”‚       â”‚
â”‚  â”‚ 3. create_embeddings â”‚      â”‚ 3. Create embeddings â”‚       â”‚
â”‚  â”‚ 4. build_vectorstore â”‚      â”‚ 4. Build vectorstore â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚             â”‚                             â”‚                    â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚                        â”‚                                       â”‚
â”‚                        â–¼                                       â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚             â”‚ build_qa_chain()     â”‚                          â”‚
â”‚             â”‚                      â”‚                          â”‚
â”‚             â”‚ â€¢ OpenAI LLM         â”‚                          â”‚
â”‚             â”‚ â€¢ Retriever (k=3)    â”‚                          â”‚
â”‚             â”‚ â€¢ RetrievalQA chain  â”‚                          â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     External Services                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ OpenAI API   â”‚    â”‚ ChromaDB     â”‚    â”‚ LangChain   â”‚     â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚             â”‚     â”‚
â”‚  â”‚ â€¢ Embeddings â”‚    â”‚ â€¢ Vector     â”‚    â”‚ â€¢ Chains    â”‚     â”‚
â”‚  â”‚ â€¢ GPT Models â”‚    â”‚   Storage    â”‚    â”‚ â€¢ Splitters â”‚     â”‚
â”‚  â”‚ â€¢ Completion â”‚    â”‚ â€¢ Similarity â”‚    â”‚ â€¢ Prompts   â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Data Flow

### Upload Mode Flow

```
User Upload
    â”‚
    â”œâ”€ .txt/.md â”€â”€â†’ UTF-8 Decode â”€â”€â”
    â”‚                               â”‚
    â”œâ”€ .pdf â”€â”€â†’ PyPDF2 Extract â”€â”€â”€â”€â”¤
    â”‚                               â”‚
    â””â”€ .csv â”€â”€â†’ Pandas to_string â”€â”€â”˜
                                    â”‚
                                    â–¼
                            Raw Text String
                                    â”‚
                                    â–¼
                    RecursiveCharacterTextSplitter
                    (chunk_size=800, overlap=100)
                                    â”‚
                                    â–¼
                            Text Chunks []
                                    â”‚
                                    â–¼
                        OpenAI Embeddings API
                                    â”‚
                                    â–¼
                            Vector Embeddings
                                    â”‚
                                    â–¼
                            ChromaDB Store
                                    â”‚
                                    â–¼
                                Retriever
                                    â”‚
                                    â–¼
                            RetrievalQA Chain
                                    â”‚
                                    â–¼
                            Ready for Queries
```

### Query Processing Flow

```
User Query
    â”‚
    â–¼
QA Chain
    â”‚
    â”œâ”€â”€â†’ Vectorstore.similarity_search(query, k=3)
    â”‚         â”‚
    â”‚         â–¼
    â”‚    Top 3 Relevant Chunks
    â”‚         â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
Prompt Construction
    â”‚
    â”œâ”€ System Context
    â”œâ”€ Retrieved Chunks
    â””â”€ User Question
    â”‚
    â–¼
OpenAI API Call
    â”‚
    â–¼
LLM Response
    â”‚
    â–¼
Display to User
```

---

## ğŸ—‚ï¸ File Structure

```
rag-demo-data-engineering/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Streamlit UI with dual modes
â”‚   â”œâ”€â”€ rag_engine.py        # Core RAG logic + upload processing
â”‚   â””â”€â”€ prompts.py           # Discovery prompt library
â”‚
â”œâ”€â”€ data/                    # Pre-loaded knowledge base
â”‚   â”œâ”€â”€ *.txt               # Data engineering documents
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env                     # API keys (not in git)
â”œâ”€â”€ .env.template           # Template for .env
â”‚
â”œâ”€â”€ README.md               # Main documentation
â”œâ”€â”€ UPLOAD_GUIDE.md         # Upload feature guide
â”œâ”€â”€ SETUP_INSTRUCTIONS.md   # Quick setup
â”œâ”€â”€ ARCHITECTURE.md         # This file
â”œâ”€â”€ CHANGELOG.md            # Version history
â”‚
â””â”€â”€ test_upload.py          # Test script
```

---

## ğŸ§© Key Components

### 1. Frontend Layer (`main.py`)

**Responsibilities:**
- User interface and interaction
- Mode selection (upload vs pre-loaded)
- File upload handling
- Session state management
- Error display and user feedback

**Technologies:**
- Streamlit for UI
- Session state for persistence
- File uploader widget

---

### 2. Processing Layer (`rag_engine.py`)

**Responsibilities:**
- Text extraction from multiple formats
- Document chunking
- Embedding generation
- Vector store management
- QA chain construction

**Key Functions:**

#### `extract_text(file)`
- **Input**: Uploaded file object
- **Process**: Format detection and extraction
- **Output**: Raw text string

#### `process_uploaded_file(file)`
- **Input**: Uploaded file object
- **Process**: Complete pipeline (extract â†’ chunk â†’ embed â†’ store)
- **Output**: ChromaDB vectorstore

#### `load_documents(path)`
- **Input**: Directory path
- **Process**: Load all .txt files
- **Output**: List of document strings

#### `create_vectorstore(docs)`
- **Input**: List of documents
- **Process**: Chunk and embed documents
- **Output**: ChromaDB vectorstore

#### `build_qa_chain(vectorstore)`
- **Input**: Vectorstore
- **Process**: Create LLM + retriever chain
- **Output**: RetrievalQA chain

---

### 3. External Services

#### OpenAI API
- **Purpose**: Embeddings and LLM
- **Usage**:
  - `OpenAIEmbeddings()` - Convert text to vectors
  - `OpenAI(temperature=0.3)` - Generate responses

#### ChromaDB
- **Purpose**: Vector database
- **Usage**:
  - Store embeddings
  - Similarity search
  - Document retrieval

#### LangChain
- **Purpose**: Orchestration framework
- **Usage**:
  - Text splitting
  - Chain construction
  - Prompt management

---

## âš™ï¸ Configuration

### Environment Variables (`.env`)

```bash
# Required
OPENAI_API_KEY=sk-...

# Optional (for local LLM)
OPENAI_API_BASE=http://localhost:11434/v1
```

### RAG Parameters

```python
# Chunking
chunk_size = 800          # Characters per chunk
chunk_overlap = 100       # Overlap between chunks

# Retrieval
k = 3                     # Number of chunks to retrieve

# LLM
temperature = 0.3         # Creativity level (0-1)
```

---

## ğŸ” Security Considerations

1. **API Key Management**
   - Store in `.env` file (not in git)
   - Use environment variables
   - Rotate keys regularly

2. **File Upload Safety**
   - Validate file types
   - Limit file sizes
   - Sanitize file names

3. **Data Privacy**
   - Uploaded files processed in memory
   - Vectors stored locally in ChromaDB
   - API calls to OpenAI (review their privacy policy)

---

## ğŸš€ Performance Optimization

### Current Implementation
- **Upload Processing**: ~5-10 seconds per document
- **First Query**: ~2-3 seconds
- **Subsequent Queries**: ~1-2 seconds

### Optimization Strategies
1. **Caching**: Store vectorstores for reuse
2. **Batch Processing**: Process multiple documents together
3. **Lazy Loading**: Load embeddings on-demand
4. **Local Embeddings**: Use local models to reduce API calls

---

## ğŸ”® Future Architecture Enhancements

### Phase 1: Performance
- Vector persistence (save/load)
- Response caching
- Async processing

### Phase 2: Features
- Batch upload
- Metadata filtering
- Cross-encoder re-ranking

### Phase 3: Scale
- API endpoints
- Multi-user support
- Production deployment
- Monitoring and analytics

---

## ğŸ“Š Technical Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Frontend** | Streamlit | Interactive UI |
| **Backend** | Python 3.8+ | Core logic |
| **Text Processing** | PyPDF2, pandas | Multi-format support |
| **Chunking** | LangChain | Text splitting |
| **Embeddings** | OpenAI API | Vector generation |
| **Vector DB** | ChromaDB | Semantic search |
| **LLM** | OpenAI GPT | Answer generation |
| **Orchestration** | LangChain | RAG pipeline |

---

**Architecture Version:** 2.0  
**Last Updated:** October 21, 2025  
**Built in:** NeuquÃ©n, Argentina ğŸ‡¦ğŸ‡·
